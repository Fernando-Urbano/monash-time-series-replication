\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{indentfirst}
\usepackage{amsmath}

\title{Summary of the Monash \\ Time Series Forecasting Archive}

\date{March $11^{th}$, 2024}

\begin{document}

\maketitle

In this project we attempt to replicate results from a 2021 paper on the motivation and creation of the Monash Time Series Forecasting Archive, a project spearheaded by a group time series researchers from Monash University and the University of Sydney.

\section{Paper Importance}
The Monash Archive is an essential asset to time series researchers as it provides a comprehensive benchmark time series forecasting archive to evaluate the performance of new global and multivariate forecasting algorithms. Specifically, as researchers branch further and further into the machine learning space, the Monash Archive allows them to test the generalized performance of their models against well-tested benchmark models, which is beneficial in addressing the questions of model overfitting and performance. 

The archive contains datasets spanning multiple domains (industries) as well as 13 forecasting models, 6 of which are canonical univariate models, and 7 of which are global models that have shown positive results in recent years. In the following sections we provide a brief description of each of the datasets used, as well as an overview of the important aspects of the models used. 

\section{Data Sources}
The archive repository contains 25 datasets where each data point is an individual time series, with most being of variable length. The datasets indicated as multivariate in Table 1 are constrained to have time series that are all of the same length so that multivariate forecasting models may be run on them without error. Additionally there are 5 datasets which contain a single very long time series. From these 30 primary datasets the authors have created 58 total datasets, where some are split according to differing model frequencies, and  datasets with missing values are split into two datasets: one with and one without the missing values. It should be noted that global univariate and local univariate can be applied to all datasets in the repository.

We now go into further depth concerning each of the primary datasets:

\subsection{Collections of multiple time series}
This section describes the benchmark datasets that have a sufficient number of series from a particular
frequency. The datasets may contain different categories in terms of domain and frequency.

\subsubsection{M1 dataset}
This dataset is from the M1 forecasting competition held in the year 1982. It contains 1001 time series with 3 different frequencies (monthly, quarterly, yearly) and is one of few belonging to multiple domains.

\subsubsection{M3 dataset}
This dataset is from the M3 forecasting competition held in the year 2000. It contains 3003 time series with 4 different frequencies (monthly, quarterly, yearly, other) and is one of few belonging to multiple domains.

\subsubsection{M4 dataset}
This dataset is from the M4 forecasting competition held in the year 2020. It contains 100,000 time series with 6 different frequencies (hourly, daily, weekly, monthly, quarterly, yearly) and is one of few belonging to multiple domains.

\subsubsection{Tourism dataset}
This dataset originates from a kaggle competition. It contains 1311 tourism related time series with 3 different frequencies (monthly, quarterly, yearly).

\subsubsection{NN5 dataset}
This dataset is from the NN5 neural forecasting competition held in the year 2008. It contains 111 daily time series of cash withdrawals from ATMs in the U.K. The original dataset contained missing values that were filled in by the authors of the paper using a median substitution method.

\subsubsection{CIF 2016 dataset}
This dataset is from the Computational Intelligence in Forecasting (CIF) competition held in 2016. It contains 72 monthly time series, where 24 originate from the banking sector and the other 48 are artificially generated. There are two datasets corresponding to different forecast horizons: 6 and 12.

\subsubsection{Kaggle web traffic dataset}
This dataset is from the Kaggle web traffic forecasting competition held in the year 2017. It contains 145063 daily time series representing the number of hits for a set of pages on Wikipedia from 01/07/2015 to 10/09/2017. The authors also include their own aggregated version of weekly time series. 

\subsubsection{Solar dataset}
This dataset corresponds to the solar power production in the state of Alabama throughout the year 2006. It contains 137 time series representing the amount of solar power produced every 10 minutes. The authors also include their own aggregated version of weekly time series. 

\subsubsection{Electricity dataset}
This dataset corresponds to the amount of electricity consumed per hour by 321 clients, collected from 2012 to 2014 by UC Irvine. The authors also include their own aggregated version of weekly time series.

\subsubsection{London smart meters dataset}
This dataset corresponds to the energy consumption readings of London households in kWh from November 2011 to February 2014. It contains 5560 half-hourly time series. Two versions are included: one with missing values, and one where the missing values are filled in using the last observation carried forward (LOCF) method. 

\subsubsection{Australian electricity demand dataset}
This dataset corresponds to the electricity demand of 5 Australian states: Victoria, New South Wales, Queensland, Tasmania and South Australia. It contains 5 half-hourly time series.

\subsubsection{Wind farms dataset}
This dataset contains very long minutely time series representing the wind power production of 339
wind farms in Australia. It is curated by the authors and is not available elsewhere. Two versions are included: one with missing values, and one where the missing values have been set to zero.

\subsubsection{Car parts dataset}
This dataset contains 2674 intermittent monthly time series showing car parts sales from January
1998 to March 2002. Two versions are included: one with missing values, and one where the missing values have been set to zero.

\subsubsection{Dominick dataset}
This dataset corresponds to the profit of individual stock keeping units (SKUs) from a retailer collected from the online platform of the University of Chicago Booth School of Business Kilts Center. It contains 115704 weekly time series.

\subsubsection{FRED-MD dataset}
This dataset was extracted from the FRED-MD database and corresponds to  a set of macro-economic indicators from the Federal Reserve Bank. It contains 107 monthly time series starting from  01/01/1959.

\subsubsection{Bitcoin dataset}
This dataset shows the potential factors influencing bitcoin price (such as transaction values and hash rate). It contains 18 daily time series, 2 of which show the public opinion of bitcoins in the form of tweets and google searches mentioning the keyword, bitcoin. It is curated by the authors and is not available elsewhere. Two versions are included: one with missing values, and one where the missing values are filled in using the LOCF method.

\subsubsection{San Francisco Traffic dataset}
This dataset corresponds to the road occupancy rates on San Francisco Bay area freeways. It contains 862 hourly time series taken from 2015 to 2016. The authors also include their own aggregated version of weekly time series.

\subsubsection{Melbourne pedestrian counts dataset}
This dataset contains hourly time series of pedestrian counts captured from 66 sensors in Melbourne from May 2009 to April 30, 2020.

\subsubsection{Rideshare dataset}
This dataset corresponds to attributes related to Uber and Lyft rideshare services (such as price and distance) for different locations in New York from 26/11/2018 to 18/12/2018. It contains 2304 hourly time series. Two versions are included: one with missing values, and one where the missing values have been set to zero.

\subsubsection{Vehicle trips dataset}
This dataset corresponds to the number of trips and vehicles belonging to a set of for-hire vehicle (FHV) companies in 2015, extracted from fivethirtyeight. It contains 329 daily time series. Two versions are included: one with missing values, and one where the missing values are filled in using the LOCF method.

\subsubsection{Hospital dataset}
This dataset corresponds to e patient counts related to medical products from January 2000 to December 2006. It contains 767 monthly time series.

\subsubsection{COVID deaths dataset}
This dataset represents the total COVID-19 deaths in a set of countries and states from 22/01/2020 to 20/08/2020, extracted from the Johns Hopkins repository. It contains 266 daily time series.

\subsubsection{KDD cup 2018 dataset}
This dataset originates from a 2018 competition. It contains 270 long hourly time series representing  the air quality levels in 59 stations from 2 cities, Beijing (35 stations) and London (24 stations) from 01/01/2017 to 31/03/2018. It represents the air quality across multiple measurements.

\subsubsection{Weather dataset}
This dataset contains 3010 daily time series of four weather variables: rain, minimum temperature,
maximum temperature, and solar radiation, measured at weather stations in Australia.

\subsubsection{Temperature rain dataset}
This dataset corresponds to the temperature/rainfall observations and forecasts, gathered by the Australian Bureau of Meteorology for 422 weather stations across Australia, between 02/05/2015 and 26/04/2017. It contains 32072 daily time series. Two versions are included: one with missing values, and one where the missing values have been set to zero.

\subsection{Single long time series datasets}
This section describes the benchmark datasets which have single time series with a large amount of
data points.

\subsubsection{Sunspot dataset}
This dataset contains the single daily time series representing the sunspot numbers from 08/01/1818
to 31/05/2020. Two versions are included: one with missing values, and one where the missing values are filled in using the LOCF method.

\subsubsection{Saugeen river flow dataset}
This dataset contains a single very long time series representing the daily mean flow of the Saugeen
River at Walkerton in cubic meters per second from 01/01/1915 to 31/12/1979. The length of the time series is 23,741.

\subsubsection{US Births dataset}
This dataset contains a single very long daily time series representing the number of births in the US
from 01/01/1969 to 31/12/1988. The length of the time series is 7,305.

\subsubsection{Solar power dataset}
This dataset contains a single very long time series representing the solar power production of an
Australian wind farm recorded every 4 seconds starting from 01/08/2019. The length of the time
series is 7,397,222.

\subsubsection{Wind power dataset}
This dataset contains a single very long time series representing the wind power production of an
Australian wind farm recorded every 4 seconds starting from 01/08/2019. The length of the time
series is 7,397,147.

\section{Models/Evaluation}

\subsection{Models}
As previously mentioned this project uses 6 traditional univariate models, and 7 global models, covering a representative set of state-of-the-art forecasting models from statistical, machine learning, and deep learning domains, for a total of 13 models.

The 6 traditional models used are Exponential Smoothing (ETS), Auto-Regressive Integrated Moving Average (ARIMA), Simple Exponential Smoothing
(SES), Theta, Trigonometric Box-Cox ARMA Trend Seasonal (TBATS), and Dynamic Harmonic Regression ARIMA (DHR-ARIMA). The 7 global forecasting models used are a linear Pooled Regression model (PR), a Feed-Forward Neural Network (FFNN), CatBoost, DeepAR, N-BEATS, a WaveNet, and a Transformer method. As there is extensive literature on each of these models we forego any description here. 

We implement the 6 traditional univariate models as well as PR and CatBoost in R using the packages forecast, glmnet, and catboost. The authors of the original paper used R base version 4.0.2 but we use R base version 4.3.2. The other models are implemented in Python using the GluonTS package from AWS. The authors of the original paper used Python 3.7.4 and GluonTS 0.8.0. This presented challenges for us that will be expounded upon later. Since all models are presented as benchmarks for baseline model performance, no hyperparameter tuning is done and the models are presented with their default hyperparameters. 

\subsection{Model Evaluation}
For evaluating the performance of the models, the authors compared the Mean Absolute Scaled Error (MASE) of each of the models per dataset. This statistic was calculated by using forecasting functions created by the authors of the original paper (and publicly available on github) to calculate the MASE per time series in each of the datasets and then calculating the mean value across the MASE results per dataset. The formula for this is given below $$\text{MASE}=\frac{\sum_{k=M+1}^{M+h} |F_k-Y_k|}{\frac{h}{M-S}\sum_{k=S+1}^{M} |Y_{k+1}-Y_k|}$$
where $M$ is the number of data points in the training series, $S$ is the seasonality of the dataset, $h$ is the forecast horizon, $F_k$ are the generated forecasts, and $Y_k$ are the actual values. 

The MASE results per model (columns) per dataset (rows) are given in Table 2.

\section{Replication Performance}
The goal of our replication project was to successfully load the datasets, implement the authors functions with minimal updates, and regenerate Table 1 and Table 2 from the original paper in similar formatting. This proved to be a project primarily rooted in understanding effective package managing and resolving software conflicts related to cross-package version dependencies. We were successfully able to run all the models using R on a significant portion of the datasets but had lingering, unresolvable issues on the GluonTS models and some datasets. We will now briefly describe these successes, failures, and some recommendations, given our current knowledge, for the future of this replication project. 

\subsection{Successes}
We were successfully able to run the R models on a significant portion of the datasets. 

We used an Anaconda environment and initially encountered problems with package installations from the authors' indicated R package versions resulting from the fact that the authors originally used an R base version of 4.0.2, which was unable to be installed in current versions of Anaconda. We instead used an R base version of 4.3.2 and were able to bypass these restrictions by manually adding the packages in our conda environment through including several "install.packages()" statements in our R forecasting scripts. However, there was an issue in building one of the dependency packages resulting from system incompatibilities with the underlying C and Fortran used to write the packages. We found that in order to successfully build the packages the user must first install cmake through homebrew on their machine. We also found through resolving these issues that it is essential to use the libmamba solver in one's conda environment as opposed to the classic solver. 

Additionally, when we were finally able to run the R models on the datasets, we found that some models took an infeasible amount of time to run on local machines for certain datasets (on the order of 4 hours for a single model on a single dataset). This indicated to us that it would be wiser to run these models on an HPC cluster. However, as non faculty or staff researchers, the University of Chicago will not grant us access to the Midway Clusters and so we were unable to run these datasets in the final product in the interest of time and reproducibility. 

For the datasets that we were successfully able to run, we found near identical results to the authors of the original paper (with a maximum error of $\approx$ 0.001)!

\subsection{Failures}
We were not as fortunate in running the Python models as we were in running the R models. In addition to our inability to run a few of the datasets, we had several issues related to Python package versioning primarily resulting from Conda's poor ability to run versions of Python and Python packages that are more than 2 years out-of-date (currently, the Python packages the paper's authors used are nearly 3 years out-of-date).

These issues began with a massive update in the GluonTS package between 2021 (version 0.8.0) and today (version 0.14.4) which significantly altered the declarations of model objects. This update made it so that the authors' model functions were declaring functional arguments for the GluonTS model objects that no longer existed in the GluonTS documentation. As GluonTS is primarily based on the complex machine learning libraries PyTorch and MXnet, and none of our group members had the knowledge of these libraries to update the authors' functions, our only option was to attempt to downgrade the version of GluonTS from 0.14.4 to 0.8.0 and resolve any resulting dependency conflicts in the Conda environment. 

Our group member attempting to resolve these issues was working using a homebrew installation of the miniforge distribution of mamba, while the rest of the group was working in the traditional installation of Anaconda3. The miniforge distribution provided much more versatility, however we required, based on the parameters of this project, that any solution be implementable using the conventional installation of Anaconda3. We were able to find a package configuration that passed running "pip check" for dependency conflicts and contained package versions very close to the package requirements of GluonTS version 0.8.0 (which was found on github). However, this configuration required the version of Python to be 3.7.6 (close to the author's version of Python 3.7.4), and the oldest version of Python available given the new anaconda update to Conda version 24.1.2 (which is required to run the R models), was Python 3.8.5. This presented an insurmountable conflict that we were not able to overcome without overhauling the entire project and starting from scratch using an alternate package manager.

\subsection{Recommendations} 
For attempting this project again in the future, we recommend using either the miniforge distribution of mamba, or an entirely different package manager from Anaconda altogether. In researching our dependency conflicts, we found that the main advantage of the  Miniconda distribution as opposed to the full Anaconda distribution is that Miniconda only ships with the repository management system as well as a limited number of base python packages, whereas Anaconda ships with 150+ python packages as well as several other modules (AWS, JupyterLab, JupyterNotebook, etc.) that are unnecessary for this project. Thus, the limited available versions of python and necessary python packages in Anaconda results from needless incompatibilities with system packages that aren't even used in this project. In light of this information, the best course of action may be to simply use pip as the package manager in a local virtual environment which bypasses Conda altogether, as this would provide the highest degree of versatility in using outdated package versions.


\end{document}
